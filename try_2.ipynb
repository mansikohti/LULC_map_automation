{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a10f5cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.features import shapes, rasterize\n",
    "from rasterio.windows import from_bounds, Window\n",
    "from shapely.geometry import shape, box\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce620b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training shapefile and preparing geometries...\n",
      "Training features loaded: 26\n",
      "Features intersecting raster extent: 26 / 26\n",
      "Sampling training pixels (windowed per polygon)...\n",
      "Sampled pixels: 52000, bands: 4\n",
      "Training Random Forest...\n",
      "Training completed.\n",
      "Internal accuracy (holdout):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.54      0.56      1600\n",
      "           2       0.41      0.41      0.41      2400\n",
      "           5       0.64      0.65      0.64      2000\n",
      "           7       0.51      0.53      0.52      2000\n",
      "           8       0.54      0.54      0.54      2400\n",
      "\n",
      "    accuracy                           0.53     10400\n",
      "   macro avg       0.54      0.54      0.54     10400\n",
      "weighted avg       0.53      0.53      0.53     10400\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 865  221   82  186  246]\n",
      " [ 192  988  322  438  460]\n",
      " [  74  265 1298  160  203]\n",
      " [ 131  444  154 1066  205]\n",
      " [ 204  488  183  220 1305]]\n",
      "Classifying raster blockwise and polygonizing on-the-fly...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 128. MiB for an array with shape (3350432, 1, 5) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"d:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\joblib\\_utils.py\", line 72, in __call__\n    return self.func(**kwargs)\n           ~~~~~~~~~^^^^^^^^^^\n  File \"d:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\joblib\\parallel.py\", line 607, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n            ~~~~^^^^^^^^^^^^^^^^^\n  File \"d:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 147, in __call__\n    return self.function(*args, **kwargs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"d:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 730, in _accumulate_prediction\n    prediction = predict(X, check_input=False)\n  File \"d:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1058, in predict_proba\n    proba = self.tree_.predict(X)\n  File \"sklearn/tree/_tree.pyx\", line 941, in sklearn.tree._tree.Tree.predict\n  File \"sklearn/tree/_tree.pyx\", line 943, in sklearn.tree._tree.Tree.predict\nnumpy._core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (3350432, 1, 5) and data type float64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 179\u001b[39m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mConfusion matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, cm)\n\u001b[32m    178\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mClassifying raster blockwise and polygonizing on-the-fly...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m gdf_polys = \u001b[43mclassify_and_polygonize_blockwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraster_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_field\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCollected polygons before dissolve: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(gdf_polys)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(gdf_polys) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 105\u001b[39m, in \u001b[36mclassify_and_polygonize_blockwise\u001b[39m\u001b[34m(raster_path, clf, class_field)\u001b[39m\n\u001b[32m    103\u001b[39m     preds = np.zeros(arr2.shape[\u001b[32m0\u001b[39m], dtype=\u001b[38;5;28mint\u001b[39m)\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.any(mask_nonzero):\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m         preds_masked = \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask_nonzero\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m         preds[mask_nonzero] = preds_masked\n\u001b[32m    107\u001b[39m preds2d = preds.reshape(h, w).astype(\u001b[33m'\u001b[39m\u001b[33mint32\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:903\u001b[39m, in \u001b[36mForestClassifier.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    883\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    884\u001b[39m \u001b[33;03m    Predict class for X.\u001b[39;00m\n\u001b[32m    885\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    901\u001b[39m \u001b[33;03m        The predicted classes.\u001b[39;00m\n\u001b[32m    902\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m     proba = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m:\n\u001b[32m    906\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.classes_.take(np.argmax(proba, axis=\u001b[32m1\u001b[39m), axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:956\u001b[39m, in \u001b[36mForestClassifier.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    951\u001b[39m all_proba = [\n\u001b[32m    952\u001b[39m     np.zeros((X.shape[\u001b[32m0\u001b[39m], j), dtype=np.float64)\n\u001b[32m    953\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m np.atleast_1d(\u001b[38;5;28mself\u001b[39m.n_classes_)\n\u001b[32m    954\u001b[39m ]\n\u001b[32m    955\u001b[39m lock = threading.Lock()\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msharedmem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimators_\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m proba \u001b[38;5;129;01min\u001b[39;00m all_proba:\n\u001b[32m    962\u001b[39m     proba /= \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\joblib\\parallel.py:1784\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1785\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1787\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\joblib\\parallel.py:1859\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\joblib\\parallel.py:758\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    752\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\joblib\\parallel.py:773\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 128. MiB for an array with shape (3350432, 1, 5) and data type float64"
     ]
    }
   ],
   "source": [
    "def load_and_prepare_training(training_shp, class_field=\"class_id\", target_crs=None):\n",
    "    gdf = gpd.read_file(training_shp)\n",
    "    if class_field not in gdf.columns:\n",
    "        raise ValueError(f\"Class field '{class_field}' not found. Available fields: {list(gdf.columns)}\")\n",
    "    gdf[class_field] = gdf[class_field].astype(int)\n",
    "    gdf = gdf[~gdf.geometry.is_empty].copy()\n",
    "    gdf['geometry'] = gdf['geometry'].buffer(0)\n",
    "    if target_crs is not None and gdf.crs != target_crs:\n",
    "        gdf = gdf.to_crs(target_crs)\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def sample_training_pixels_windowed(gdf, raster_path, class_field=\"class_id\", max_pixels_per_poly=None):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        nbands = src.count\n",
    "        raster_crs = src.crs\n",
    "        if gdf.crs != raster_crs:\n",
    "            gdf = gdf.to_crs(raster_crs)\n",
    "\n",
    "        for idx, row in gdf.iterrows():\n",
    "            geom = row.geometry\n",
    "            cls = int(row[class_field])\n",
    "            if geom is None or geom.is_empty:\n",
    "                continue\n",
    "            minx, miny, maxx, maxy = geom.bounds\n",
    "            pad_x = (maxx - minx) * 0.001 + 1e-6\n",
    "            pad_y = (maxy - miny) * 0.001 + 1e-6\n",
    "            win = from_bounds(minx - pad_x, miny - pad_y, maxx + pad_x, maxy + pad_y, transform=src.transform)\n",
    "            col_off = max(0, int(win.col_off))\n",
    "            row_off = max(0, int(win.row_off))\n",
    "            width = int(min(src.width - col_off, win.width))\n",
    "            height = int(min(src.height - row_off, win.height))\n",
    "            if width <= 0 or height <= 0:\n",
    "                continue\n",
    "            window = Window(col_off, row_off, width, height)\n",
    "            arr = src.read(window=window)\n",
    "            if arr.size == 0:\n",
    "                continue\n",
    "            window_transform = rasterio.windows.transform(window, src.transform)\n",
    "            mask = rasterize(\n",
    "                [(geom, 1)],\n",
    "                out_shape=(height, width),\n",
    "                transform=window_transform,\n",
    "                fill=0,\n",
    "                dtype='uint8'\n",
    "            )\n",
    "            pixels_idx = np.where(mask.flatten() == 1)[0]\n",
    "            if pixels_idx.size == 0:\n",
    "                continue\n",
    "            arr_reshaped = arr.reshape(nbands, -1)\n",
    "            sel_pixels = arr_reshaped[:, pixels_idx].T\n",
    "            if max_pixels_per_poly is not None and sel_pixels.shape[0] > max_pixels_per_poly:\n",
    "                choice = np.random.choice(sel_pixels.shape[0], max_pixels_per_poly, replace=False)\n",
    "                sel_pixels = sel_pixels[choice]\n",
    "            X_list.append(sel_pixels)\n",
    "            y_list.append(np.full((sel_pixels.shape[0],), cls, dtype=np.int32))\n",
    "    if len(X_list) == 0:\n",
    "        return np.zeros((0,0)), np.zeros((0,), dtype=np.int32)\n",
    "    X = np.vstack(X_list)\n",
    "    y = np.concatenate(y_list)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def train_random_forest(X, y, n_estimators=200, random_state=42):\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, n_jobs=-1, random_state=random_state)\n",
    "    clf.fit(X, y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def accuracy_report_holdout(clf, X, y, test_size=0.2):\n",
    "    if X.shape[0] < 10:\n",
    "        print(\"Not enough samples for holdout accuracy.\")\n",
    "        return None, None\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=42)\n",
    "    clf2 = RandomForestClassifier(n_estimators=clf.n_estimators, n_jobs=-1, random_state=42)\n",
    "    clf2.fit(X_train, y_train)\n",
    "    preds = clf2.predict(X_test)\n",
    "    report = metrics.classification_report(y_test, preds)\n",
    "    cm = metrics.confusion_matrix(y_test, preds)\n",
    "    return report, cm\n",
    "\n",
    "\n",
    "def classify_and_polygonize_blockwise(raster_path, clf, class_field='class_id'):\n",
    "    \"\"\"\n",
    "    Classify raster blockwise and polygonize each block's predicted classes on the fly.\n",
    "    Returns a GeoDataFrame of polygons (not yet dissolved).\n",
    "    \"\"\"\n",
    "    recs = []\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        nbands = src.count\n",
    "        for ji, window in src.block_windows(1):\n",
    "            arr = src.read(window=window)  # (bands, h, w)\n",
    "            bands, h, w = arr.shape\n",
    "            arr2 = arr.reshape(bands, -1).T\n",
    "            arr2 = np.nan_to_num(arr2, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            # predict\n",
    "            try:\n",
    "                preds = clf.predict(arr2)\n",
    "            except Exception:\n",
    "                mask_nonzero = ~(np.all(arr2 == 0, axis=1))\n",
    "                preds = np.zeros(arr2.shape[0], dtype=int)\n",
    "                if np.any(mask_nonzero):\n",
    "                    preds_masked = clf.predict(arr2[mask_nonzero])\n",
    "                    preds[mask_nonzero] = preds_masked\n",
    "            preds2d = preds.reshape(h, w).astype('int32')\n",
    "            # polygonize only non-zero classes\n",
    "            window_transform = rasterio.windows.transform(window, src.transform)\n",
    "            mask = preds2d != 0\n",
    "            if not np.any(mask):\n",
    "                continue\n",
    "            for geom_json, val in shapes(preds2d, mask=mask, transform=window_transform):\n",
    "                recs.append({ 'geometry': shape(geom_json), class_field: int(val) })\n",
    "    if len(recs) == 0:\n",
    "        return gpd.GeoDataFrame(columns=['geometry', class_field])\n",
    "    gdf = gpd.GeoDataFrame(recs)\n",
    "    # set CRS from source raster\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        gdf.crs = src.crs\n",
    "    return gdf\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# MAIN: user parameters\n",
    "# -----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # ---------- USER PARAMETERS (edit) ----------\n",
    "    raster_path = r\"D:/2_Analytics/9_LULC_classification/demo_ortho/KRB_BGD_ORTHO_3CM_UTM_GEOTIFF.tif\"\n",
    "    training_shp = r\"D:/2_Analytics/9_LULC_classification/training_shp/training_shp.shp\"\n",
    "    class_field = \"class_id\"\n",
    "    out_vector = r\"D:/2_Analytics/9_LULC_classification/classified_polygons.shp\"\n",
    "    rf_n_estimators = 200\n",
    "    max_samples_per_polygon = 2000\n",
    "\n",
    "    legend = {\n",
    "        1: (\"Water\", \"#1f78b4\"),\n",
    "        2: (\"Built-up\", \"#b15928\"),\n",
    "        3: (\"Vegetation\", \"#33a02c\"),\n",
    "        4: (\"Bare soil\", \"#fdbf6f\"),\n",
    "        5: (\"Road\", \"#6a3d9a\"),\n",
    "        6: (\"Shadow\", \"#666666\"),\n",
    "        7: (\"Agriculture\", \"#b2df8a\"),\n",
    "        8: (\"Forest\", \"#228B22\"),\n",
    "    }\n",
    "    # -------------------------------------------\n",
    "\n",
    "    print(\"Loading training shapefile and preparing geometries...\")\n",
    "    with rasterio.open(raster_path) as _src:\n",
    "        raster_crs = _src.crs\n",
    "        raster_bounds = _src.bounds\n",
    "\n",
    "    gdf = load_and_prepare_training(training_shp, class_field=class_field, target_crs=raster_crs)\n",
    "    print(f\"Training features loaded: {len(gdf)}\")\n",
    "\n",
    "    bbox = box(*raster_bounds)\n",
    "    gdf_in = gdf[gdf.geometry.intersects(bbox)]\n",
    "    print(f\"Features intersecting raster extent: {len(gdf_in)} / {len(gdf)}\")\n",
    "    if len(gdf_in) == 0:\n",
    "        raise RuntimeError(\"No training polygons intersect the raster. Check CRS and locations.\")\n",
    "\n",
    "    print(\"Sampling training pixels (windowed per polygon)...\")\n",
    "    X, y = sample_training_pixels_windowed(gdf_in, raster_path, class_field=class_field, max_pixels_per_poly=max_samples_per_polygon)\n",
    "    print(f\"Sampled pixels: {X.shape[0]}, bands: {X.shape[1] if X.size else 0}\")\n",
    "    if X.shape[0] == 0:\n",
    "        raise RuntimeError(\"No training pixels sampled. Check raster and polygons.\")\n",
    "\n",
    "    print(\"Training Random Forest...\")\n",
    "    clf = train_random_forest(X, y, n_estimators=rf_n_estimators)\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "    print(\"Internal accuracy (holdout):\")\n",
    "    report, cm = accuracy_report_holdout(clf, X, y)\n",
    "    if report is not None:\n",
    "        print(report)\n",
    "        print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "    print(\"Classifying raster blockwise and polygonizing on-the-fly...\")\n",
    "    gdf_polys = classify_and_polygonize_blockwise(raster_path, clf, class_field=class_field)\n",
    "    print(f\"Collected polygons before dissolve: {len(gdf_polys)}\")\n",
    "\n",
    "    if len(gdf_polys) == 0:\n",
    "        raise RuntimeError(\"No polygons generated from classification. Exiting.\")\n",
    "\n",
    "    # dissolve by class_id\n",
    "    gdf_polys = gdf_polys.set_crs(raster_crs)\n",
    "    gdf_dissolved = gdf_polys.dissolve(by=class_field, as_index=False)\n",
    "\n",
    "    # add class_name from legend\n",
    "    name_map = {k: v[0] for k, v in legend.items()}\n",
    "    color_map = {k: v[1] for k, v in legend.items()}\n",
    "    gdf_dissolved['class_name'] = gdf_dissolved[class_field].map(name_map).fillna('unknown')\n",
    "\n",
    "    # save legend CSV next to vector\n",
    "    legend_csv = os.path.splitext(out_vector)[0] + \"_legend.csv\"\n",
    "    with open(legend_csv, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"class_id,class_name,color\\n\")\n",
    "        for cid, (nm, col) in legend.items():\n",
    "            f.write(f\"{cid},{nm},{col}\\n\")\n",
    "    print(\"Saved legend CSV to:\", legend_csv)\n",
    "\n",
    "    # write vector\n",
    "    gdf_dissolved.to_file(out_vector, driver='ESRI Shapefile')\n",
    "    print(\"Saved polygon vector to:\", out_vector)\n",
    "\n",
    "    print(\"Done. No TIFF outputs were created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "795d46db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping (name -> code): {'water': 1, 'forest': 2, 'buildup': 3, 'roads': 4, 'agriculture': 5, 'unclassified': 0}\n",
      "Shapefile counts per class (raw polygons): {'forest': 1, 'agriculture': 1, 'roads': 1, 'water': 1, 'buildup': 1}\n",
      "Raster size: 104701 x 121220; Bands: 4\n",
      "Training polygons intersecting raster: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collect windows: 100%|██████████| 48585/48585 [00:05<00:00, 8100.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected samples: 7732344 features: 4\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 59.0 MiB for an array with shape (7732344, 1) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"d:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\joblib\\_utils.py\", line 72, in __call__\n    return self.func(**kwargs)\n           ~~~~~~~~~^^^^^^^^^^\n  File \"d:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\joblib\\parallel.py\", line 607, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n            ~~~~^^^^^^^^^^^^^^^^^\n  File \"d:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 147, in __call__\n    return self.function(*args, **kwargs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"d:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 188, in _parallel_build_trees\n    tree._fit(\n    ~~~~~~~~~^\n        X,\n        ^^\n    ...<3 lines>...\n        missing_values_in_feature_mask=missing_values_in_feature_mask,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"d:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 303, in _fit\n    y_encoded = np.zeros(y.shape, dtype=int)\nnumpy._core._exceptions._ArrayMemoryError: Unable to allocate 59.0 MiB for an array with shape (7732344, 1) and data type int64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 396\u001b[39m\n\u001b[32m    393\u001b[39m model_file = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mD:/2_Analytics/9_LULC_classification/demo_ortho/rf_model.joblib\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    395\u001b[39m \u001b[38;5;66;03m# Run pipeline (will print progress)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m results = \u001b[43mrun_full_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraster_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_shp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_field\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclass\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwater\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbuildup\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mroads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magriculture\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43munclassified\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtile_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_out\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrgb_out\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_rgb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_out\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtreat_zeros_as_nodata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# set True if your ortho background is black and should be treated as nodata\u001b[39;49;00m\n\u001b[32m    409\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFinished. Outputs:\u001b[39m\u001b[33m\"\u001b[39m, results)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 354\u001b[39m, in \u001b[36mrun_full_pipeline\u001b[39m\u001b[34m(raster_path, shp_path, class_field, user_classes, tile_size, n_estimators, max_samples, label_out, rgb_out, model_out, verbose, treat_zeros_as_nodata)\u001b[39m\n\u001b[32m    348\u001b[39m X, y = collect_training_samples(\n\u001b[32m    349\u001b[39m     \u001b[38;5;28mstr\u001b[39m(raster_path), \u001b[38;5;28mstr\u001b[39m(shp_path), class_field, mapping,\n\u001b[32m    350\u001b[39m     tile_size=tile_size, max_samples=max_samples, verbose=verbose, treat_zeros_as_nodata=treat_zeros_as_nodata\n\u001b[32m    351\u001b[39m )\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# 7) Train RF\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m clf = \u001b[43mtrain_rf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    355\u001b[39m dump(clf, \u001b[38;5;28mstr\u001b[39m(model_out))\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 218\u001b[39m, in \u001b[36mtrain_rf\u001b[39m\u001b[34m(X, y, n_estimators, verbose)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_rf\u001b[39m(X, y, n_estimators=\u001b[32m100\u001b[39m, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    217\u001b[39m     clf = RandomForestClassifier(n_estimators=n_estimators, n_jobs=-\u001b[32m1\u001b[39m, class_weight=\u001b[33m\"\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m\"\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m    220\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTrained RandomForest on\u001b[39m\u001b[33m\"\u001b[39m, X.shape[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33msamples.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:486\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    475\u001b[39m trees = [\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    478\u001b[39m ]\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\joblib\\parallel.py:1784\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1785\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1787\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\joblib\\parallel.py:1859\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\joblib\\parallel.py:758\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    752\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1_code\\code_LULC_classification\\lulc_cls_env\\Lib\\site-packages\\joblib\\parallel.py:773\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 59.0 MiB for an array with shape (7732344, 1) and data type int64"
     ]
    }
   ],
   "source": [
    "# ===== Install deps if needed (uncomment) =====\n",
    "# !pip install rasterio geopandas scikit-learn numpy tqdm joblib\n",
    "\n",
    "# ===== Full pipeline with checks + colorized RGB output =====\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio import windows\n",
    "from rasterio.features import rasterize\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import dump\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "# --------------------\n",
    "# Helper / check funcs\n",
    "# --------------------\n",
    "def check_files_exist(raster_path, shp_path):\n",
    "    rp = Path(raster_path)\n",
    "    sp = Path(shp_path)\n",
    "    if not rp.exists():\n",
    "        raise FileNotFoundError(f\"Raster not found: {rp}\")\n",
    "    if not sp.exists():\n",
    "        raise FileNotFoundError(f\"Shapefile not found: {sp}\")\n",
    "    # shapefile requires .shp and its sidecar files; at minimum check .shp exists\n",
    "    return True\n",
    "\n",
    "def safe_read_gdf(shp_path):\n",
    "    try:\n",
    "        gdf = gpd.read_file(shp_path)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to read shapefile '{shp_path}': {e}\")\n",
    "    if gdf.empty:\n",
    "        raise RuntimeError(\"Shapefile contains no features.\")\n",
    "    return gdf\n",
    "\n",
    "def build_mapping_from_user_and_gdf(user_classes, gdf, class_field):\n",
    "    \"\"\"\n",
    "    Use user_classes order as primary. If shapefile contains additional classes,\n",
    "    append them after user_classes and warn.\n",
    "    Returns mapping name->code (int) with 'unclassified' mapped to 0 if present.\n",
    "    \"\"\"\n",
    "    # clean shapefile class names\n",
    "    gdf[class_field] = gdf[class_field].astype(str).str.strip().str.lower()\n",
    "    shp_unique = list(sorted(set(gdf[class_field].unique())))\n",
    "    mapping = {}\n",
    "    code = 1\n",
    "    # start with user classes if provided\n",
    "    if user_classes:\n",
    "        for cname in user_classes:\n",
    "            key = str(cname).strip().lower()\n",
    "            if key == \"unclassified\":\n",
    "                mapping[key] = 0\n",
    "            else:\n",
    "                if key not in mapping:\n",
    "                    mapping[key] = code\n",
    "                    code += 1\n",
    "    # include any shapefile classes not present\n",
    "    extra = [c for c in shp_unique if c not in mapping]\n",
    "    if extra:\n",
    "        warnings.warn(f\"Shapefile contains classes not in user_classes: {extra}. They will be appended to the mapping.\")\n",
    "        for cname in extra:\n",
    "            if cname == \"unclassified\":\n",
    "                mapping[cname] = 0\n",
    "            else:\n",
    "                mapping[cname] = code\n",
    "                code += 1\n",
    "    return mapping\n",
    "\n",
    "def windows_from_raster_obj(src, tile_size):\n",
    "    nrows, ncols = src.height, src.width\n",
    "    for row_off in range(0, nrows, tile_size):\n",
    "        height = min(tile_size, nrows - row_off)\n",
    "        for col_off in range(0, ncols, tile_size):\n",
    "            width = min(tile_size, ncols - col_off)\n",
    "            yield Window(row_off=row_off, col_off=col_off, height=height, width=width)\n",
    "\n",
    "# -------------------------\n",
    "# Training sample extraction\n",
    "# -------------------------\n",
    "def collect_training_samples(raster_path, shp_path, class_field, mapping,\n",
    "                             tile_size=512, max_samples=200000, verbose=False, treat_zeros_as_nodata=False):\n",
    "    \"\"\"\n",
    "    Windowed rasterize-then-sample approach. Returns X (n_samples x bands) and y (n_samples,)\n",
    "    \"\"\"\n",
    "    # read shapefile\n",
    "    gdf = safe_read_gdf(shp_path)\n",
    "    if class_field not in gdf.columns:\n",
    "        raise ValueError(f\"class_field '{class_field}' not in shapefile columns: {list(gdf.columns)}\")\n",
    "    # normalize class strings\n",
    "    gdf[class_field] = gdf[class_field].astype(str).str.strip().str.lower()\n",
    "\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        raster_crs = src.crs\n",
    "        band_count = src.count\n",
    "        if band_count < 3:\n",
    "            warnings.warn(f\"Raster has {band_count} bands. Expected RGB (3 bands) — still proceeding but check your input.\")\n",
    "        # reproject gdf to raster CRS if needed\n",
    "        if gdf.crs is None:\n",
    "            raise RuntimeError(\"Shapefile has no CRS. Assign a CRS in QGIS or geopandas before running.\")\n",
    "        if raster_crs != gdf.crs:\n",
    "            if verbose:\n",
    "                print(f\"Reprojecting shapefile from {gdf.crs} to raster CRS {raster_crs}.\")\n",
    "            gdf = gdf.to_crs(raster_crs)\n",
    "        # spatial index\n",
    "        try:\n",
    "            sindex = gdf.sindex\n",
    "        except Exception:\n",
    "            sindex = None\n",
    "\n",
    "        X_list = []\n",
    "        y_list = []\n",
    "        total_samples = 0\n",
    "\n",
    "        # quick check: do any polygons intersect raster extent?\n",
    "        raster_box = box(*src.bounds)\n",
    "        intersect_count = int(gdf.intersects(raster_box).sum())\n",
    "        if intersect_count == 0:\n",
    "            raise RuntimeError(\"No training polygons intersect the raster extent. Check CRS and geometry locations.\")\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Raster size: {src.width} x {src.height}; Bands: {band_count}\")\n",
    "            print(f\"Training polygons intersecting raster: {intersect_count}\")\n",
    "\n",
    "        for win in tqdm(list(windows_from_raster_obj(src, tile_size)), desc=\"Collect windows\"):\n",
    "            win_bounds = windows.bounds(win, src.transform)  # (left, bottom, right, top)\n",
    "            # candidate polygons\n",
    "            if sindex is not None:\n",
    "                candidate_idx = list(sindex.intersection(win_bounds))\n",
    "                if not candidate_idx:\n",
    "                    continue\n",
    "                sub = gdf.iloc[candidate_idx]\n",
    "                # precise intersect\n",
    "                sub = sub[sub.intersects(box(*win_bounds))]\n",
    "                if sub.empty:\n",
    "                    continue\n",
    "            else:\n",
    "                sub = gdf[gdf.intersects(box(*win_bounds))]\n",
    "                if sub.empty:\n",
    "                    continue\n",
    "\n",
    "            # shapes for rasterize\n",
    "            shapes = []\n",
    "            for _, row in sub.iterrows():\n",
    "                cname = str(row[class_field]).strip().lower()\n",
    "                if cname in mapping:\n",
    "                    shapes.append((row.geometry, int(mapping[cname])))\n",
    "            if not shapes:\n",
    "                continue\n",
    "\n",
    "            # rasterize labels for the window\n",
    "            win_transform = windows.transform(win, src.transform)\n",
    "            label = rasterize(\n",
    "                shapes,\n",
    "                out_shape=(win.height, win.width),\n",
    "                transform=win_transform,\n",
    "                fill=0,\n",
    "                all_touched=True,\n",
    "                dtype=\"uint8\"\n",
    "            )\n",
    "\n",
    "            # read image window\n",
    "            img = src.read(window=win)  # (bands, h, w)\n",
    "            # mask nodata or all-zero background\n",
    "            if src.nodata is not None:\n",
    "                mask = np.any(img == src.nodata, axis=0)\n",
    "            else:\n",
    "                if treat_zeros_as_nodata:\n",
    "                    mask = np.all(img == 0, axis=0)\n",
    "                else:\n",
    "                    mask = np.zeros((win.height, win.width), dtype=bool)\n",
    "\n",
    "            flat_label = label.ravel()\n",
    "            flat_img = img.reshape((img.shape[0], -1)).T  # (n_pixels, bands)\n",
    "            flat_mask = mask.ravel()\n",
    "\n",
    "            cond = (flat_label > 0) & (~flat_mask)\n",
    "            if np.any(cond):\n",
    "                X_list.append(flat_img[cond])\n",
    "                y_list.append(flat_label[cond])\n",
    "                total_samples += int(cond.sum())\n",
    "\n",
    "            if max_samples and total_samples >= max_samples:\n",
    "                if verbose:\n",
    "                    print(f\"Reached max_samples={max_samples}. Collected {total_samples} samples.\")\n",
    "                break\n",
    "\n",
    "    if not X_list:\n",
    "        raise RuntimeError(\"No training samples were collected. Check shapefile geometry, class_field, and CRS.\")\n",
    "\n",
    "    X = np.vstack(X_list)\n",
    "    y = np.hstack(y_list)\n",
    "\n",
    "    # downsample uniformly if too many samples\n",
    "    if max_samples and X.shape[0] > max_samples:\n",
    "        if verbose:\n",
    "            print(f\"Downsampling training samples from {X.shape[0]} to {max_samples}\")\n",
    "        rng = np.random.default_rng(42)\n",
    "        idx = rng.choice(X.shape[0], size=max_samples, replace=False)\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Collected samples:\", X.shape[0], \"features:\", X.shape[1])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# -------------------------\n",
    "# Train and prediction funcs\n",
    "# -------------------------\n",
    "def train_rf(X, y, n_estimators=100, verbose=False):\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, n_jobs=-1, class_weight=\"balanced\", random_state=42)\n",
    "    clf.fit(X, y)\n",
    "    if verbose:\n",
    "        print(\"Trained RandomForest on\", X.shape[0], \"samples.\")\n",
    "    return clf\n",
    "\n",
    "def classify_to_label_tiff(raster_path, label_out_path, clf, out_dtype=\"uint8\", tile_size=512, verbose=False, treat_zeros_as_nodata=False):\n",
    "    \"\"\"\n",
    "    Classify window-by-window and write single-band integer label TIFF.\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        meta = src.meta.copy()\n",
    "        meta.update({\"count\": 1, \"dtype\": out_dtype, \"compress\": \"lzw\", \"tiled\": True})\n",
    "        with rasterio.open(label_out_path, \"w\", **meta) as dst:\n",
    "            for win in tqdm(list(windows_from_raster_obj(src, tile_size)), desc=\"Classify windows\"):\n",
    "                img = src.read(window=win)  # (bands, h, w)\n",
    "                h, w = win.height, win.width\n",
    "                flat = img.reshape((img.shape[0], -1)).T  # (n_pixels, bands)\n",
    "\n",
    "                if src.nodata is not None:\n",
    "                    mask = np.any(img == src.nodata, axis=0).ravel()\n",
    "                    valid_idx = ~mask\n",
    "                else:\n",
    "                    if treat_zeros_as_nodata:\n",
    "                        mask = np.all(img == 0, axis=0).ravel()\n",
    "                        valid_idx = ~mask\n",
    "                    else:\n",
    "                        valid_idx = np.ones(flat.shape[0], dtype=bool)\n",
    "\n",
    "                pred = np.zeros(flat.shape[0], dtype=np.uint8)\n",
    "                if np.any(valid_idx):\n",
    "                    # predict only on valid pixels\n",
    "                    pred_valid = clf.predict(flat[valid_idx])\n",
    "                    pred[valid_idx] = pred_valid\n",
    "\n",
    "                out_arr = pred.reshape((h, w)).astype(out_dtype)\n",
    "                dst.write(out_arr, 1, window=win)\n",
    "    if verbose:\n",
    "        print(\"Wrote label TIFF to:\", label_out_path)\n",
    "\n",
    "def create_rgb_tiff_from_label(label_tiff, rgb_out_path, mapping, color_by_name, tile_size=512, verbose=False):\n",
    "    \"\"\"\n",
    "    Create a 3-band RGB GeoTIFF by mapping integer labels to RGB colors (windowed).\n",
    "    mapping: dict name->code\n",
    "    color_by_name: dict name->(R,G,B)\n",
    "    \"\"\"\n",
    "    # build code->color mapping\n",
    "    code2color = {}\n",
    "    for name, code in mapping.items():\n",
    "        col = color_by_name.get(name, (255, 0, 255))  # fallback magenta\n",
    "        # ensure tuple of 3 ints\n",
    "        col = tuple(int(c) for c in col)\n",
    "        code2color[int(code)] = col\n",
    "\n",
    "    with rasterio.open(label_tiff) as src_label:\n",
    "        meta = src_label.meta.copy()\n",
    "        meta.update({\"count\": 3, \"dtype\": \"uint8\", \"compress\": \"lzw\", \"tiled\": True})\n",
    "        with rasterio.open(rgb_out_path, \"w\", **meta) as dst_rgb:\n",
    "            for win in tqdm(list(src_label.block_windows(1)), desc=\"Colorize windows\"):\n",
    "                ji, win_obj = win\n",
    "                lbl = src_label.read(1, window=win_obj)  # (h,w)\n",
    "                h, w = lbl.shape\n",
    "                rgb = np.zeros((3, h, w), dtype=np.uint8)\n",
    "                # vectorized mapping: iterate codes present\n",
    "                vals = np.unique(lbl)\n",
    "                for v in vals:\n",
    "                    if v in code2color:\n",
    "                        r, g, b = code2color[v]\n",
    "                    else:\n",
    "                        # unknown label -> black\n",
    "                        r, g, b = (0, 0, 0)\n",
    "                    mask = (lbl == v)\n",
    "                    rgb[0][mask] = r\n",
    "                    rgb[1][mask] = g\n",
    "                    rgb[2][mask] = b\n",
    "                dst_rgb.write(rgb, window=win_obj)\n",
    "    if verbose:\n",
    "        print(\"Wrote RGB TIFF to:\", rgb_out_path)\n",
    "\n",
    "# -------------------------\n",
    "# Main wrapper with checks\n",
    "# -------------------------\n",
    "def run_full_pipeline(\n",
    "    raster_path,\n",
    "    shp_path,\n",
    "    class_field=\"class\",\n",
    "    user_classes=None,\n",
    "    tile_size=512,\n",
    "    n_estimators=100,\n",
    "    max_samples=200000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,\n",
    "    label_out=\"classified_labels.tif\",\n",
    "    rgb_out=\"classified_rgb.tif\",\n",
    "    model_out=\"rf_model.joblib\",\n",
    "    verbose=True,\n",
    "    treat_zeros_as_nodata=False\n",
    "):\n",
    "    raster_path = Path(raster_path)\n",
    "    shp_path = Path(shp_path)\n",
    "    label_out = Path(label_out)\n",
    "    rgb_out = Path(rgb_out)\n",
    "    model_out = Path(model_out)\n",
    "\n",
    "    # 1) basic filesystem checks\n",
    "    check_files_exist(raster_path, shp_path)\n",
    "\n",
    "    # 2) read shapefile and confirm class_field\n",
    "    gdf = safe_read_gdf(shp_path)\n",
    "    if class_field not in gdf.columns:\n",
    "        raise ValueError(f\"class_field '{class_field}' not found. Available fields: {list(gdf.columns)}\")\n",
    "\n",
    "    # 3) open raster to get metadata and check tile_size sanity\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        if tile_size <= 0:\n",
    "            raise ValueError(\"tile_size must be > 0\")\n",
    "        if tile_size > max(src.width, src.height):\n",
    "            warnings.warn(\"tile_size is larger than raster dimensions; using raster size windows will still work.\")\n",
    "        raster_crs = src.crs\n",
    "        if raster_crs is None:\n",
    "            raise RuntimeError(\"Raster has no CRS. Cannot safely align shapefile. Exiting.\")\n",
    "\n",
    "    # 4) build class mapping (user order first, append extras from shapefile)\n",
    "    mapping = build_mapping_from_user_and_gdf(user_classes, gdf, class_field)\n",
    "\n",
    "    # 5) show mapping and counts per class in shapefile\n",
    "    gdf[class_field] = gdf[class_field].astype(str).str.strip().str.lower()\n",
    "    counts = gdf[class_field].value_counts().to_dict()\n",
    "    if verbose:\n",
    "        print(\"Class mapping (name -> code):\", mapping)\n",
    "        print(\"Shapefile counts per class (raw polygons):\", counts)\n",
    "\n",
    "    # 6) Collect training samples\n",
    "    X, y = collect_training_samples(\n",
    "        str(raster_path), str(shp_path), class_field, mapping,\n",
    "        tile_size=tile_size, max_samples=max_samples, verbose=verbose, treat_zeros_as_nodata=treat_zeros_as_nodata\n",
    "    )\n",
    "\n",
    "    # 7) Train RF\n",
    "    clf = train_rf(X, y, n_estimators=n_estimators, verbose=verbose)\n",
    "    dump(clf, str(model_out))\n",
    "    if verbose:\n",
    "        print(\"Saved RF model to:\", model_out)\n",
    "\n",
    "    # 8) Classify to label TIFF\n",
    "    classify_to_label_tiff(str(raster_path), str(label_out), clf, out_dtype=\"uint8\", tile_size=tile_size, verbose=verbose, treat_zeros_as_nodata=treat_zeros_as_nodata)\n",
    "\n",
    "    # 9) Save mapping JSON\n",
    "    mapping_file = label_out.with_suffix(\".classes.json\")\n",
    "    with open(mapping_file, \"w\") as f:\n",
    "        json.dump(mapping, f, indent=2)\n",
    "    if verbose:\n",
    "        print(\"Saved class mapping to:\", mapping_file)\n",
    "\n",
    "    # 10) Create RGB color map (you can customize colors here)\n",
    "    # Default color palette (change as desired)\n",
    "    color_by_name = {\n",
    "        \"water\":       (0, 0, 255),\n",
    "        \"forest\":      (34, 139, 34),\n",
    "        \"buildup\":     (200, 200, 200),\n",
    "        \"roads\":       (255, 255, 0),\n",
    "        \"agriculture\": (255, 165, 0),\n",
    "        \"unclassified\":(0, 0, 0)\n",
    "    }\n",
    "    # If shapefile had extra classes not in defaults, fallback magenta for unknown names\n",
    "\n",
    "    create_rgb_tiff_from_label(str(label_out), str(rgb_out), mapping, color_by_name, tile_size=tile_size, verbose=verbose)\n",
    "\n",
    "    return {\"model\": str(model_out), \"labels\": str(label_out), \"rgb\": str(rgb_out), \"mapping\": str(mapping_file)}\n",
    "\n",
    "# -------------------------\n",
    "# Run (edit these paths to your real files)\n",
    "# -------------------------\n",
    "#raster_input = r\"D:/2_Analytics/9_LULC_classification/demo_ortho/cropped_ortho.tif\"\n",
    "raster_input = r\"D:\\2_Analytics\\9_LULC_classification\\demo_ortho\\KRB_BGD_ORTHO_3CM_UTM_GEOTIFF.tif\"\n",
    "training_shp = r\"D:\\2_Analytics\\9_LULC_classification\\training_shp\\training_new.shp\"\n",
    "output_label = r\"D:/2_Analytics/9_LULC_classification/demo_ortho/classified_rf_labels.tif\"\n",
    "output_rgb = r\"D:/2_Analytics/9_LULC_classification/demo_ortho/classified_rf_rgb.tif\"\n",
    "model_file = r\"D:/2_Analytics/9_LULC_classification/demo_ortho/rf_model.joblib\"\n",
    "\n",
    "# Run pipeline (will print progress)\n",
    "results = run_full_pipeline(\n",
    "    raster_input,\n",
    "    training_shp,\n",
    "    class_field=\"class\",\n",
    "    user_classes=[\"water\",\"forest\",\"buildup\",\"roads\",\"agriculture\",\"unclassified\"],\n",
    "    tile_size=512,\n",
    "    n_estimators=100,\n",
    "    max_samples=2000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,\n",
    "    label_out=output_label,\n",
    "    rgb_out=output_rgb,\n",
    "    model_out=model_file,\n",
    "    verbose=True,\n",
    "    treat_zeros_as_nodata=False  # set True if your ortho background is black and should be treated as nodata\n",
    ")\n",
    "\n",
    "print(\"Finished. Outputs:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8046ae41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping (name -> code): {'agriculture': 1, 'buildup': 2, 'forest': 3, 'roads': 4, 'water': 5}\n",
      "Raster size: 104701 x 121220; Bands: 4\n",
      "Training polygons intersecting raster: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collect windows: 100%|██████████| 48585/48585 [00:06<00:00, 7810.23it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected samples: 7732344 features: 4\n",
      "\n",
      "Per-class training pixel value ranges:\n",
      "\n",
      "agriculture (code=1, samples=228131)\n",
      "  Band 1: 102 – 221\n",
      "  Band 2: 83 – 200\n",
      "  Band 3: 57 – 174\n",
      "  Band 4: 255 – 255\n",
      "\n",
      "buildup (code=2, samples=343643)\n",
      "  Band 1: 25 – 253\n",
      "  Band 2: 18 – 247\n",
      "  Band 3: 11 – 244\n",
      "  Band 4: 255 – 255\n",
      "\n",
      "forest (code=3, samples=6672913)\n",
      "  Band 1: 27 – 249\n",
      "  Band 2: 18 – 243\n",
      "  Band 3: 0 – 212\n",
      "  Band 4: 255 – 255\n",
      "\n",
      "roads (code=4, samples=151947)\n",
      "  Band 1: 76 – 232\n",
      "  Band 2: 50 – 199\n",
      "  Band 3: 26 – 163\n",
      "  Band 4: 255 – 255\n",
      "\n",
      "water (code=5, samples=335710)\n",
      "  Band 1: 47 – 198\n",
      "  Band 2: 38 – 182\n",
      "  Band 3: 15 – 162\n",
      "  Band 4: 255 – 255\n",
      "\n",
      "Saved value ranges to: geoai_landcover_output\\class_value_ranges.json\n"
     ]
    }
   ],
   "source": [
    "# ====== Report per-class pixel value ranges from training data ======\n",
    "# Requires collect_training_samples() defined earlier\n",
    "\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# ---------- Edit paths ----------\n",
    "raster_input = r\"D:\\2_Analytics\\9_LULC_classification\\demo_ortho\\KRB_BGD_ORTHO_3CM_UTM_GEOTIFF.tif\"\n",
    "training_shp = r\"D:\\2_Analytics\\9_LULC_classification\\training_shp\\training_new.shp\"\n",
    "class_field = \"class\"\n",
    "out_json = Path(\"geoai_landcover_output\") / \"class_value_ranges.json\"\n",
    "out_json.parent.mkdir(parents=True, exist_ok=True)\n",
    "# --------------------------------\n",
    "\n",
    "# Build mapping from shapefile classes\n",
    "gdf = gpd.read_file(training_shp)\n",
    "gdf[class_field] = gdf[class_field].astype(str).str.strip().str.lower()\n",
    "unique_labels = sorted(gdf[class_field].unique())\n",
    "mapping = {}\n",
    "code = 1\n",
    "for name in unique_labels:\n",
    "    if name == \"unclassified\":\n",
    "        mapping[name] = 0\n",
    "    else:\n",
    "        mapping[name] = code\n",
    "        code += 1\n",
    "print(\"Mapping (name -> code):\", mapping)\n",
    "\n",
    "# Collect training samples\n",
    "X, y = collect_training_samples(\n",
    "    raster_path=raster_input,\n",
    "    shp_path=training_shp,\n",
    "    class_field=class_field,\n",
    "    mapping=mapping,\n",
    "    tile_size=512,\n",
    "    max_samples=20000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,\n",
    "    verbose=True,\n",
    "    treat_zeros_as_nodata=False\n",
    ")\n",
    "\n",
    "# Compute ranges per class\n",
    "n_bands = X.shape[1]\n",
    "ranges = {}\n",
    "for name, code in mapping.items():\n",
    "    if code == 0:\n",
    "        continue\n",
    "    mask = (y == code)\n",
    "    if not np.any(mask):\n",
    "        ranges[name] = {\"code\": code, \"count\": 0, \"band_ranges\": []}\n",
    "        continue\n",
    "    class_vals = X[mask]  # (N_class_samples, n_bands)\n",
    "    band_ranges = []\n",
    "    for b in range(n_bands):\n",
    "        vmin = int(class_vals[:, b].min())\n",
    "        vmax = int(class_vals[:, b].max())\n",
    "        band_ranges.append({\"band\": b+1, \"min\": vmin, \"max\": vmax})\n",
    "    ranges[name] = {\"code\": code, \"count\": int(mask.sum()), \"band_ranges\": band_ranges}\n",
    "\n",
    "# Print neatly\n",
    "print(\"\\nPer-class training pixel value ranges:\")\n",
    "for name, info in ranges.items():\n",
    "    print(f\"\\n{name} (code={info['code']}, samples={info['count']})\")\n",
    "    for br in info[\"band_ranges\"]:\n",
    "        print(f\"  Band {br['band']}: {br['min']} – {br['max']}\")\n",
    "\n",
    "# Save to JSON\n",
    "with open(out_json, \"w\") as f:\n",
    "    json.dump(ranges, f, indent=2)\n",
    "print(\"\\nSaved value ranges to:\", out_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff6cd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified subsample: target samples per class: 40000\n",
      " - agriculture (code=1): available=228,131, selected=40,000\n",
      " - buildup (code=2): available=343,643, selected=40,000\n",
      " - forest (code=3): available=6,672,913, selected=40,000\n",
      " - roads (code=4): available=151,947, selected=40,000\n",
      " - water (code=5): available=335,710, selected=40,000\n",
      "Final training set shape: (200000, 3) (200000,)\n",
      "Training RandomForestClassifier with n_estimators= 100 n_jobs= 1\n",
      "Model trained and saved to: D:/2_Analytics/9_LULC_classification/demo_ortho/rf_model.joblib\n",
      "Starting windowed prediction...\n"
     ]
    }
   ],
   "source": [
    "# ====== Stratified subsample, train RF safely, then predict & colorize ======\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio import windows\n",
    "from collections import Counter\n",
    "from joblib import dump\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------- Config ----------\n",
    "# Adjust these to control memory/time tradeoffs\n",
    "samples_per_class = 40000    # <= choose 20k..100k depending on available RAM/CPU\n",
    "total_max_samples = None     # optional hard cap (None to use samples_per_class * n_classes)\n",
    "rf_n_estimators = 100        # fewer trees -> less memory/time\n",
    "rf_n_jobs = 1                # IMPORTANT: avoid -1 to reduce memory spikes\n",
    "rf_random_state = 42\n",
    "\n",
    "raster_input = r\"D:\\2_Analytics\\9_LULC_classification\\demo_ortho\\KRB_BGD_ORTHO_3CM_UTM_GEOTIFF.tif\"\n",
    "output_label = r\"D:/2_Analytics/9_LULC_classification/demo_ortho/classified_rf_labels.tif\"\n",
    "output_rgb   = r\"D:/2_Analytics/9_LULC_classification/demo_ortho/classified_rf_rgb.tif\"\n",
    "model_file   = r\"D:/2_Analytics/9_LULC_classification/demo_ortho/rf_model.joblib\"\n",
    "mapping_json = Path(\"geoai_landcover_output\") / \"class_value_ranges.json\"\n",
    "\n",
    "# color_by_name as before (edit if needed)\n",
    "color_by_name = {\n",
    "    \"agriculture\": (255, 200, 0),\n",
    "    \"buildup\":     (200, 200, 200),\n",
    "    \"forest\":      (34, 139, 34),\n",
    "    \"roads\":       (180, 180, 180),\n",
    "    \"water\":       (0, 0, 255),\n",
    "    \"unclassified\":(0, 0, 0)\n",
    "}\n",
    "tile_size = 512\n",
    "\n",
    "# ---------- Ensure X,y exist ----------\n",
    "if \"X\" not in globals() or \"y\" not in globals():\n",
    "    raise RuntimeError(\"X,y not found in notebook. Run the sample collection cell first.\")\n",
    "\n",
    "# If more than 3 bands, keep first 3\n",
    "if X.shape[1] > 3:\n",
    "    X = X[:, :3]\n",
    "\n",
    "# Build inverse mapping (name->code) must exist\n",
    "if \"mapping\" not in globals():\n",
    "    if mapping_json.exists():\n",
    "        # mapping was saved in a previous JSON (ranges file): load it\n",
    "        info = json.load(open(mapping_json, \"r\"))\n",
    "        # if the saved structure is ranges, convert to mapping\n",
    "        if isinstance(info, dict) and all(\"code\" in v for v in info.values()):\n",
    "            mapping = {name:int(v[\"code\"]) for name,v in info.items()}\n",
    "        else:\n",
    "            # try fallback: if info is mapping directly\n",
    "            mapping = {k:int(v) for k,v in info.items()}\n",
    "    else:\n",
    "        raise RuntimeError(\"mapping not in memory and mapping JSON not found.\")\n",
    "\n",
    "inv_map = {v:k for k,v in mapping.items()}  # code->name\n",
    "\n",
    "# ---------- Stratified subsample ----------\n",
    "print(\"Stratified subsample: target samples per class:\", samples_per_class)\n",
    "unique_codes = sorted([c for n,c in mapping.items() if int(c) != 0])  # skip code 0 (unclassified)\n",
    "per_class_idx = {}\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "for code in unique_codes:\n",
    "    idxs = np.nonzero(y == code)[0]\n",
    "    n = idxs.size\n",
    "    if n == 0:\n",
    "        print(f\"Warning: no samples for code {code} ({inv_map.get(code,'?')})\")\n",
    "        per_class_idx[code] = np.array([], dtype=int)\n",
    "        continue\n",
    "    if n <= samples_per_class:\n",
    "        chosen = idxs\n",
    "    else:\n",
    "        chosen = rng.choice(idxs, size=samples_per_class, replace=False)\n",
    "    per_class_idx[code] = chosen\n",
    "    print(f\" - {inv_map.get(code,'?')} (code={code}): available={n:,}, selected={chosen.size:,}\")\n",
    "\n",
    "# Combine indices\n",
    "all_idx = np.hstack([per_class_idx[c] for c in unique_codes if per_class_idx[c].size>0])\n",
    "if total_max_samples:\n",
    "    if all_idx.size > total_max_samples:\n",
    "        all_idx = rng.choice(all_idx, size=total_max_samples, replace=False)\n",
    "\n",
    "# Shuffle combined indices\n",
    "perm = rng.permutation(all_idx.size)\n",
    "all_idx = all_idx[perm]\n",
    "\n",
    "X_sub = X[all_idx]\n",
    "y_sub = y[all_idx]\n",
    "print(\"Final training set shape:\", X_sub.shape, y_sub.shape)\n",
    "\n",
    "# Free some memory by deleting big X,y if you won't use them later\n",
    "# del X, y   # uncomment if you want\n",
    "\n",
    "# ---------- Train RandomForest (safer params) ----------\n",
    "print(\"Training RandomForestClassifier with n_estimators=\", rf_n_estimators, \"n_jobs=\", rf_n_jobs)\n",
    "clf = RandomForestClassifier(n_estimators=rf_n_estimators, n_jobs=rf_n_jobs,\n",
    "                             class_weight=\"balanced\", random_state=rf_random_state)\n",
    "clf.fit(X_sub, y_sub)\n",
    "dump(clf, model_file)\n",
    "print(\"Model trained and saved to:\", model_file)\n",
    "\n",
    "# ---------- Predict full raster (windowed) ----------\n",
    "print(\"Starting windowed prediction...\")\n",
    "with rasterio.open(raster_input) as src:\n",
    "    meta = src.meta.copy()\n",
    "    meta.update({\"count\": 1, \"dtype\": \"uint8\", \"compress\": \"lzw\", \"tiled\": True})\n",
    "    with rasterio.open(output_label, \"w\", **meta) as dst:\n",
    "        # iterate windows in the same tiling pattern used earlier\n",
    "        for row_off in range(0, src.height, tile_size):\n",
    "            for col_off in range(0, src.width, tile_size):\n",
    "                height = min(tile_size, src.height - row_off)\n",
    "                width = min(tile_size, src.width - col_off)\n",
    "                win = windows.Window(col_off=col_off, row_off=row_off, width=width, height=height)\n",
    "                img = src.read(window=win)  # (bands, h, w)\n",
    "                if img.shape[0] > 3:\n",
    "                    img = img[:3, :, :]\n",
    "                h, w = win.height, win.width\n",
    "                flat = img.reshape((img.shape[0], -1)).T\n",
    "\n",
    "                if src.nodata is not None:\n",
    "                    mask = np.any(img == src.nodata, axis=0).ravel()\n",
    "                    valid_idx = ~mask\n",
    "                else:\n",
    "                    valid_idx = np.ones(flat.shape[0], dtype=bool)\n",
    "\n",
    "                pred = np.zeros(flat.shape[0], dtype=np.uint8)\n",
    "                if np.any(valid_idx):\n",
    "                    pred_valid = clf.predict(flat[valid_idx])\n",
    "                    pred[valid_idx] = pred_valid\n",
    "\n",
    "                out_arr = pred.reshape((h, w)).astype(np.uint8)\n",
    "                dst.write(out_arr, 1, window=win)\n",
    "\n",
    "print(\"Label TIFF written to:\", output_label)\n",
    "\n",
    "# ---------- Colorized RGB TIFF ----------\n",
    "print(\"Colorizing label TIFF to RGB...\")\n",
    "code2color = {int(code): color_by_name.get(name, (255,0,255)) for name,code in mapping.items()}\n",
    "with rasterio.open(output_label) as src_label:\n",
    "    meta = src_label.meta.copy()\n",
    "    meta.update({\"count\": 3, \"dtype\": \"uint8\", \"compress\": \"lzw\", \"tiled\": True})\n",
    "    with rasterio.open(output_rgb, \"w\", **meta) as dst_rgb:\n",
    "        for ji, win in src_label.block_windows(1):\n",
    "            lbl = src_label.read(1, window=win)\n",
    "            h, w = lbl.shape\n",
    "            rgb = np.zeros((3, h, w), dtype=np.uint8)\n",
    "            vals = np.unique(lbl)\n",
    "            for v in vals:\n",
    "                col = code2color.get(int(v), (0,0,0))\n",
    "                mask = (lbl == v)\n",
    "                rgb[0][mask] = col[0]\n",
    "                rgb[1][mask] = col[1]\n",
    "                rgb[2][mask] = col[2]\n",
    "            dst_rgb.write(rgb, window=win)\n",
    "\n",
    "print(\"RGB TIFF written to:\", output_rgb)\n",
    "\n",
    "# ---------- Pixel counts ----------\n",
    "from collections import Counter\n",
    "with rasterio.open(output_label) as src:\n",
    "    counts = Counter()\n",
    "    for ji, win in src.block_windows(1):\n",
    "        data = src.read(1, window=win)\n",
    "        vals, cnt = np.unique(data, return_counts=True)\n",
    "        for v,c in zip(vals, cnt):\n",
    "            counts[int(v)] += int(c)\n",
    "\n",
    "inv_map = {v:k for k,v in mapping.items()}\n",
    "print(\"\\nPixel counts per class:\")\n",
    "for code, cnt in sorted(counts.items()):\n",
    "    name = inv_map.get(code, \"unknown\")\n",
    "    print(f\" {code:>2d} ({name:12s}): {cnt:,}\")\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4339bada",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lulc_cls_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
